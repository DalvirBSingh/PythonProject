{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Library Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (35887, 2304)\n",
      "Y shape (35887,)\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(48, 48, 1..., padding=\"same\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), padding=\"same\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 4,478,727\n",
      "Trainable params: 4,474,759\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n",
      "Train on 32298 samples, validate on 3589 samples\n",
      "Epoch 1/124\n",
      "32298/32298 [==============================] - 406s 13ms/step - loss: 0.3853 - categorical_accuracy: 0.3284 - val_loss: 0.3938 - val_categorical_accuracy: 0.2984\n",
      "Epoch 2/124\n",
      "32298/32298 [==============================] - 464s 14ms/step - loss: 0.3106 - categorical_accuracy: 0.4693 - val_loss: 0.3303 - val_categorical_accuracy: 0.4076\n",
      "Epoch 3/124\n",
      "32298/32298 [==============================] - 409s 13ms/step - loss: 0.2815 - categorical_accuracy: 0.5304 - val_loss: 0.2721 - val_categorical_accuracy: 0.5386\n",
      "Epoch 4/124\n",
      "32298/32298 [==============================] - 405s 13ms/step - loss: 0.2641 - categorical_accuracy: 0.5631 - val_loss: 0.2798 - val_categorical_accuracy: 0.5316\n",
      "Epoch 5/124\n",
      "32298/32298 [==============================] - 412s 13ms/step - loss: 0.2517 - categorical_accuracy: 0.5868 - val_loss: 0.2778 - val_categorical_accuracy: 0.5358\n",
      "Epoch 6/124\n",
      "32298/32298 [==============================] - 396s 12ms/step - loss: 0.2420 - categorical_accuracy: 0.6072 - val_loss: 0.2673 - val_categorical_accuracy: 0.5380\n",
      "Epoch 7/124\n",
      "32298/32298 [==============================] - 390s 12ms/step - loss: 0.2330 - categorical_accuracy: 0.6267 - val_loss: 0.3315 - val_categorical_accuracy: 0.4185\n",
      "Epoch 8/124\n",
      "32298/32298 [==============================] - 424s 13ms/step - loss: 0.2237 - categorical_accuracy: 0.6445 - val_loss: 0.2540 - val_categorical_accuracy: 0.5874\n",
      "Epoch 9/124\n",
      "32298/32298 [==============================] - 438s 14ms/step - loss: 0.2147 - categorical_accuracy: 0.6621 - val_loss: 0.2617 - val_categorical_accuracy: 0.5851\n",
      "Epoch 10/124\n",
      "32298/32298 [==============================] - 395s 12ms/step - loss: 0.2043 - categorical_accuracy: 0.6808 - val_loss: 0.2500 - val_categorical_accuracy: 0.5991\n",
      "Epoch 11/124\n",
      "32298/32298 [==============================] - 504s 16ms/step - loss: 0.1972 - categorical_accuracy: 0.6961 - val_loss: 0.2452 - val_categorical_accuracy: 0.6163\n",
      "Epoch 12/124\n",
      "32298/32298 [==============================] - 472s 15ms/step - loss: 0.1876 - categorical_accuracy: 0.7144 - val_loss: 0.2602 - val_categorical_accuracy: 0.5926\n",
      "Epoch 13/124\n",
      "32298/32298 [==============================] - 449s 14ms/step - loss: 0.1769 - categorical_accuracy: 0.7343 - val_loss: 0.2388 - val_categorical_accuracy: 0.6383\n",
      "Epoch 14/124\n",
      "32298/32298 [==============================] - 415s 13ms/step - loss: 0.1671 - categorical_accuracy: 0.7512 - val_loss: 0.2735 - val_categorical_accuracy: 0.5784\n",
      "Epoch 15/124\n",
      "32298/32298 [==============================] - 425s 13ms/step - loss: 0.1581 - categorical_accuracy: 0.7666 - val_loss: 0.2458 - val_categorical_accuracy: 0.6258\n",
      "Epoch 16/124\n",
      "32298/32298 [==============================] - 422s 13ms/step - loss: 0.1491 - categorical_accuracy: 0.7802 - val_loss: 0.2497 - val_categorical_accuracy: 0.6422\n",
      "Epoch 17/124\n",
      "32298/32298 [==============================] - 452s 14ms/step - loss: 0.1365 - categorical_accuracy: 0.8041 - val_loss: 0.2606 - val_categorical_accuracy: 0.6425\n",
      "Epoch 18/124\n",
      "32298/32298 [==============================] - 440s 14ms/step - loss: 0.1293 - categorical_accuracy: 0.8149 - val_loss: 0.2602 - val_categorical_accuracy: 0.6289\n",
      "Epoch 19/124\n",
      "32298/32298 [==============================] - 432s 13ms/step - loss: 0.1213 - categorical_accuracy: 0.8280 - val_loss: 0.3360 - val_categorical_accuracy: 0.5612\n",
      "Epoch 20/124\n",
      "32298/32298 [==============================] - 414s 13ms/step - loss: 0.1111 - categorical_accuracy: 0.8461 - val_loss: 0.2822 - val_categorical_accuracy: 0.6027\n",
      "Epoch 21/124\n",
      "32298/32298 [==============================] - 402s 12ms/step - loss: 0.1040 - categorical_accuracy: 0.8531 - val_loss: 0.2888 - val_categorical_accuracy: 0.6358\n",
      "Epoch 22/124\n",
      "32298/32298 [==============================] - 393s 12ms/step - loss: 0.0981 - categorical_accuracy: 0.8653 - val_loss: 0.2876 - val_categorical_accuracy: 0.6325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/124\n",
      "32298/32298 [==============================] - 400s 12ms/step - loss: 0.0901 - categorical_accuracy: 0.8769 - val_loss: 0.3166 - val_categorical_accuracy: 0.5979\n",
      "Epoch 24/124\n",
      "32298/32298 [==============================] - 421s 13ms/step - loss: 0.0873 - categorical_accuracy: 0.8798 - val_loss: 0.3202 - val_categorical_accuracy: 0.6077\n",
      "Epoch 25/124\n",
      "32298/32298 [==============================] - 423s 13ms/step - loss: 0.0814 - categorical_accuracy: 0.8907 - val_loss: 0.3066 - val_categorical_accuracy: 0.6269\n",
      "Epoch 26/124\n",
      "32298/32298 [==============================] - 417s 13ms/step - loss: 0.0759 - categorical_accuracy: 0.8986 - val_loss: 0.3292 - val_categorical_accuracy: 0.6096\n",
      "Epoch 27/124\n",
      "32298/32298 [==============================] - 380s 12ms/step - loss: 0.0715 - categorical_accuracy: 0.9061 - val_loss: 0.3591 - val_categorical_accuracy: 0.6063\n",
      "Epoch 28/124\n",
      "32298/32298 [==============================] - 377s 12ms/step - loss: 0.0678 - categorical_accuracy: 0.9122 - val_loss: 0.3276 - val_categorical_accuracy: 0.6364\n",
      "Epoch 29/124\n",
      "32298/32298 [==============================] - 385s 12ms/step - loss: 0.0639 - categorical_accuracy: 0.9164 - val_loss: 0.3637 - val_categorical_accuracy: 0.6166\n",
      "Epoch 30/124\n",
      "32298/32298 [==============================] - 390s 12ms/step - loss: 0.0616 - categorical_accuracy: 0.9197 - val_loss: 0.3670 - val_categorical_accuracy: 0.6116\n",
      "Epoch 31/124\n",
      "32298/32298 [==============================] - 405s 13ms/step - loss: 0.0580 - categorical_accuracy: 0.9243 - val_loss: 0.3398 - val_categorical_accuracy: 0.6342\n",
      "Epoch 32/124\n",
      "32298/32298 [==============================] - 387s 12ms/step - loss: 0.0561 - categorical_accuracy: 0.9270 - val_loss: 0.3623 - val_categorical_accuracy: 0.5921\n",
      "Epoch 33/124\n",
      "32298/32298 [==============================] - 379s 12ms/step - loss: 0.0547 - categorical_accuracy: 0.9293 - val_loss: 0.4059 - val_categorical_accuracy: 0.5971\n",
      "Epoch 34/124\n",
      "32298/32298 [==============================] - 375s 12ms/step - loss: 0.0536 - categorical_accuracy: 0.9314 - val_loss: 0.3382 - val_categorical_accuracy: 0.6386\n",
      "Epoch 35/124\n",
      "32298/32298 [==============================] - 380s 12ms/step - loss: 0.0502 - categorical_accuracy: 0.9364 - val_loss: 0.4102 - val_categorical_accuracy: 0.6021\n",
      "Epoch 36/124\n",
      "32298/32298 [==============================] - 405s 13ms/step - loss: 0.0472 - categorical_accuracy: 0.9411 - val_loss: 0.3680 - val_categorical_accuracy: 0.6272\n",
      "Epoch 37/124\n",
      "32298/32298 [==============================] - 398s 12ms/step - loss: 0.0468 - categorical_accuracy: 0.9406 - val_loss: 0.3712 - val_categorical_accuracy: 0.6308\n",
      "Epoch 38/124\n",
      "32298/32298 [==============================] - 393s 12ms/step - loss: 0.0457 - categorical_accuracy: 0.9410 - val_loss: 0.3734 - val_categorical_accuracy: 0.6372\n",
      "Epoch 39/124\n",
      "32298/32298 [==============================] - 391s 12ms/step - loss: 0.0456 - categorical_accuracy: 0.9420 - val_loss: 0.3829 - val_categorical_accuracy: 0.6108\n",
      "Epoch 40/124\n",
      "32298/32298 [==============================] - 390s 12ms/step - loss: 0.0428 - categorical_accuracy: 0.9463 - val_loss: 0.4056 - val_categorical_accuracy: 0.6208\n",
      "Epoch 41/124\n",
      "32298/32298 [==============================] - 383s 12ms/step - loss: 0.0419 - categorical_accuracy: 0.9493 - val_loss: 0.4052 - val_categorical_accuracy: 0.6183\n",
      "Epoch 42/124\n",
      "32298/32298 [==============================] - 363s 11ms/step - loss: 0.0411 - categorical_accuracy: 0.9471 - val_loss: 0.3868 - val_categorical_accuracy: 0.6420\n",
      "Epoch 43/124\n",
      "32298/32298 [==============================] - 364s 11ms/step - loss: 0.0409 - categorical_accuracy: 0.9486 - val_loss: 0.3946 - val_categorical_accuracy: 0.6149\n",
      "Epoch 44/124\n",
      "32298/32298 [==============================] - 389s 12ms/step - loss: 0.0391 - categorical_accuracy: 0.9516 - val_loss: 0.3773 - val_categorical_accuracy: 0.6199\n",
      "Epoch 45/124\n",
      "32298/32298 [==============================] - 389s 12ms/step - loss: 0.0375 - categorical_accuracy: 0.9542 - val_loss: 0.3780 - val_categorical_accuracy: 0.6406\n",
      "Epoch 46/124\n",
      "32298/32298 [==============================] - 396s 12ms/step - loss: 0.0358 - categorical_accuracy: 0.9550 - val_loss: 0.3747 - val_categorical_accuracy: 0.6414\n",
      "Epoch 47/124\n",
      "32298/32298 [==============================] - 395s 12ms/step - loss: 0.0361 - categorical_accuracy: 0.9553 - val_loss: 0.4103 - val_categorical_accuracy: 0.6158\n",
      "Epoch 48/124\n",
      "32298/32298 [==============================] - 389s 12ms/step - loss: 0.0355 - categorical_accuracy: 0.9568 - val_loss: 0.3996 - val_categorical_accuracy: 0.6347\n",
      "Epoch 49/124\n",
      "32298/32298 [==============================] - 371s 11ms/step - loss: 0.0348 - categorical_accuracy: 0.9570 - val_loss: 0.3949 - val_categorical_accuracy: 0.6344\n",
      "Epoch 50/124\n",
      "32298/32298 [==============================] - 391s 12ms/step - loss: 0.0345 - categorical_accuracy: 0.9586 - val_loss: 0.4237 - val_categorical_accuracy: 0.6317\n",
      "Epoch 51/124\n",
      "32298/32298 [==============================] - 406s 13ms/step - loss: 0.0329 - categorical_accuracy: 0.9603 - val_loss: 0.4074 - val_categorical_accuracy: 0.6010\n",
      "Epoch 52/124\n",
      "32298/32298 [==============================] - 389s 12ms/step - loss: 0.0326 - categorical_accuracy: 0.9597 - val_loss: 0.4032 - val_categorical_accuracy: 0.6297\n",
      "Epoch 53/124\n",
      "32298/32298 [==============================] - 409s 13ms/step - loss: 0.0323 - categorical_accuracy: 0.9604 - val_loss: 0.5053 - val_categorical_accuracy: 0.5327\n",
      "Epoch 54/124\n",
      "32298/32298 [==============================] - 376s 12ms/step - loss: 0.0322 - categorical_accuracy: 0.9596 - val_loss: 0.4307 - val_categorical_accuracy: 0.6166\n",
      "Epoch 55/124\n",
      "32298/32298 [==============================] - 392s 12ms/step - loss: 0.0309 - categorical_accuracy: 0.9627 - val_loss: 0.4104 - val_categorical_accuracy: 0.6172\n",
      "Epoch 56/124\n",
      "32298/32298 [==============================] - 391s 12ms/step - loss: 0.0308 - categorical_accuracy: 0.9617 - val_loss: 0.4199 - val_categorical_accuracy: 0.6258\n",
      "Epoch 57/124\n",
      "32298/32298 [==============================] - 439s 14ms/step - loss: 0.0306 - categorical_accuracy: 0.9632 - val_loss: 0.4367 - val_categorical_accuracy: 0.6344\n",
      "Epoch 58/124\n",
      "32298/32298 [==============================] - 400s 12ms/step - loss: 0.0302 - categorical_accuracy: 0.9630 - val_loss: 0.4183 - val_categorical_accuracy: 0.6286\n",
      "Epoch 59/124\n",
      "32298/32298 [==============================] - 398s 12ms/step - loss: 0.0283 - categorical_accuracy: 0.9653 - val_loss: 0.4382 - val_categorical_accuracy: 0.6208\n",
      "Epoch 60/124\n",
      "32298/32298 [==============================] - 390s 12ms/step - loss: 0.0280 - categorical_accuracy: 0.9658 - val_loss: 0.4342 - val_categorical_accuracy: 0.6124\n",
      "Epoch 61/124\n",
      "32298/32298 [==============================] - 430s 13ms/step - loss: 0.0284 - categorical_accuracy: 0.9655 - val_loss: 0.4184 - val_categorical_accuracy: 0.6322\n",
      "Epoch 62/124\n",
      "32298/32298 [==============================] - 426s 13ms/step - loss: 0.0293 - categorical_accuracy: 0.9646 - val_loss: 0.4572 - val_categorical_accuracy: 0.5940\n",
      "Epoch 63/124\n",
      "32298/32298 [==============================] - 429s 13ms/step - loss: 0.0275 - categorical_accuracy: 0.9659 - val_loss: 0.4272 - val_categorical_accuracy: 0.6124\n",
      "Epoch 64/124\n",
      "32298/32298 [==============================] - 424s 13ms/step - loss: 0.0263 - categorical_accuracy: 0.9670 - val_loss: 0.4278 - val_categorical_accuracy: 0.6392\n",
      "Epoch 65/124\n",
      "32298/32298 [==============================] - 409s 13ms/step - loss: 0.0273 - categorical_accuracy: 0.9671 - val_loss: 0.4229 - val_categorical_accuracy: 0.6339\n",
      "Epoch 66/124\n",
      "32298/32298 [==============================] - 406s 13ms/step - loss: 0.0279 - categorical_accuracy: 0.9664 - val_loss: 0.4166 - val_categorical_accuracy: 0.6447\n",
      "Epoch 67/124\n",
      "32298/32298 [==============================] - 395s 12ms/step - loss: 0.0265 - categorical_accuracy: 0.9679 - val_loss: 0.4085 - val_categorical_accuracy: 0.6411\n",
      "Epoch 68/124\n",
      "32298/32298 [==============================] - 365s 11ms/step - loss: 0.0263 - categorical_accuracy: 0.9687 - val_loss: 0.4151 - val_categorical_accuracy: 0.6172\n",
      "Epoch 69/124\n",
      "32298/32298 [==============================] - 394s 12ms/step - loss: 0.0257 - categorical_accuracy: 0.9682 - val_loss: 0.4389 - val_categorical_accuracy: 0.6372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/124\n",
      "32298/32298 [==============================] - 387s 12ms/step - loss: 0.0255 - categorical_accuracy: 0.9683 - val_loss: 0.4183 - val_categorical_accuracy: 0.6450\n",
      "Epoch 71/124\n",
      "32298/32298 [==============================] - 413s 13ms/step - loss: 0.0257 - categorical_accuracy: 0.9688 - val_loss: 0.4565 - val_categorical_accuracy: 0.6186\n",
      "Epoch 72/124\n",
      "32298/32298 [==============================] - 429s 13ms/step - loss: 0.0251 - categorical_accuracy: 0.9697 - val_loss: 0.4519 - val_categorical_accuracy: 0.6113\n",
      "Epoch 73/124\n",
      "32298/32298 [==============================] - 421s 13ms/step - loss: 0.0248 - categorical_accuracy: 0.9699 - val_loss: 0.4346 - val_categorical_accuracy: 0.6294\n",
      "Epoch 74/124\n",
      "32298/32298 [==============================] - 421s 13ms/step - loss: 0.0252 - categorical_accuracy: 0.9685 - val_loss: 0.4368 - val_categorical_accuracy: 0.6333\n",
      "Epoch 75/124\n",
      "32298/32298 [==============================] - 441s 14ms/step - loss: 0.0239 - categorical_accuracy: 0.9701 - val_loss: 0.4364 - val_categorical_accuracy: 0.6330\n",
      "Epoch 76/124\n",
      "32298/32298 [==============================] - 410s 13ms/step - loss: 0.0236 - categorical_accuracy: 0.9703 - val_loss: 0.4368 - val_categorical_accuracy: 0.6322\n",
      "Epoch 77/124\n",
      "32298/32298 [==============================] - 460s 14ms/step - loss: 0.0243 - categorical_accuracy: 0.9711 - val_loss: 0.4300 - val_categorical_accuracy: 0.6434\n",
      "Epoch 78/124\n",
      "32298/32298 [==============================] - 421s 13ms/step - loss: 0.0235 - categorical_accuracy: 0.9716 - val_loss: 0.4316 - val_categorical_accuracy: 0.6278\n",
      "Epoch 79/124\n",
      "32298/32298 [==============================] - 429s 13ms/step - loss: 0.0222 - categorical_accuracy: 0.9732 - val_loss: 0.4500 - val_categorical_accuracy: 0.6289\n",
      "Epoch 80/124\n",
      "32298/32298 [==============================] - 436s 14ms/step - loss: 0.0230 - categorical_accuracy: 0.9731 - val_loss: 0.4401 - val_categorical_accuracy: 0.6311\n",
      "Epoch 81/124\n",
      "32298/32298 [==============================] - 417s 13ms/step - loss: 0.0231 - categorical_accuracy: 0.9715 - val_loss: 0.4629 - val_categorical_accuracy: 0.5999\n",
      "Epoch 82/124\n",
      "32298/32298 [==============================] - 437s 14ms/step - loss: 0.0215 - categorical_accuracy: 0.9738 - val_loss: 0.4284 - val_categorical_accuracy: 0.6392\n",
      "Epoch 83/124\n",
      "32298/32298 [==============================] - 447s 14ms/step - loss: 0.0230 - categorical_accuracy: 0.9720 - val_loss: 0.4497 - val_categorical_accuracy: 0.6344\n",
      "Epoch 84/124\n",
      "32298/32298 [==============================] - 456s 14ms/step - loss: 0.0209 - categorical_accuracy: 0.9740 - val_loss: 0.4223 - val_categorical_accuracy: 0.6478\n",
      "Epoch 85/124\n",
      "32298/32298 [==============================] - 454s 14ms/step - loss: 0.0213 - categorical_accuracy: 0.9743 - val_loss: 0.4383 - val_categorical_accuracy: 0.6528\n",
      "Epoch 86/124\n",
      "32298/32298 [==============================] - 419s 13ms/step - loss: 0.0221 - categorical_accuracy: 0.9724 - val_loss: 0.4597 - val_categorical_accuracy: 0.6344\n",
      "Epoch 87/124\n",
      "32298/32298 [==============================] - 408s 13ms/step - loss: 0.0226 - categorical_accuracy: 0.9726 - val_loss: 0.4265 - val_categorical_accuracy: 0.6447\n",
      "Epoch 88/124\n",
      "32298/32298 [==============================] - 436s 14ms/step - loss: 0.0206 - categorical_accuracy: 0.9757 - val_loss: 0.4485 - val_categorical_accuracy: 0.6317\n",
      "Epoch 89/124\n",
      "32298/32298 [==============================] - 412s 13ms/step - loss: 0.0215 - categorical_accuracy: 0.9731 - val_loss: 0.4545 - val_categorical_accuracy: 0.6311\n",
      "Epoch 90/124\n",
      "32298/32298 [==============================] - 423s 13ms/step - loss: 0.0204 - categorical_accuracy: 0.9764 - val_loss: 0.4597 - val_categorical_accuracy: 0.6369\n",
      "Epoch 91/124\n",
      "32298/32298 [==============================] - 417s 13ms/step - loss: 0.0203 - categorical_accuracy: 0.9758 - val_loss: 0.4458 - val_categorical_accuracy: 0.6347\n",
      "Epoch 92/124\n",
      "32298/32298 [==============================] - 435s 13ms/step - loss: 0.0204 - categorical_accuracy: 0.9747 - val_loss: 0.4765 - val_categorical_accuracy: 0.5893\n",
      "Epoch 93/124\n",
      "32298/32298 [==============================] - 417s 13ms/step - loss: 0.0198 - categorical_accuracy: 0.9763 - val_loss: 0.4526 - val_categorical_accuracy: 0.6514\n",
      "Epoch 94/124\n",
      "32298/32298 [==============================] - 427s 13ms/step - loss: 0.0195 - categorical_accuracy: 0.9772 - val_loss: 0.4574 - val_categorical_accuracy: 0.6225\n",
      "Epoch 95/124\n",
      "32298/32298 [==============================] - 390s 12ms/step - loss: 0.0205 - categorical_accuracy: 0.9741 - val_loss: 0.4623 - val_categorical_accuracy: 0.6088\n",
      "Epoch 96/124\n",
      "32298/32298 [==============================] - 412s 13ms/step - loss: 0.0198 - categorical_accuracy: 0.9763 - val_loss: 0.4865 - val_categorical_accuracy: 0.6043\n",
      "Epoch 97/124\n",
      "32298/32298 [==============================] - 418s 13ms/step - loss: 0.0199 - categorical_accuracy: 0.9760 - val_loss: 0.4630 - val_categorical_accuracy: 0.6431\n",
      "Epoch 98/124\n",
      "32298/32298 [==============================] - 400s 12ms/step - loss: 0.0190 - categorical_accuracy: 0.9774 - val_loss: 0.4530 - val_categorical_accuracy: 0.6442\n",
      "Epoch 99/124\n",
      "32298/32298 [==============================] - 391s 12ms/step - loss: 0.0198 - categorical_accuracy: 0.9763 - val_loss: 0.4668 - val_categorical_accuracy: 0.6498\n",
      "Epoch 100/124\n",
      "32298/32298 [==============================] - 393s 12ms/step - loss: 0.0186 - categorical_accuracy: 0.9773 - val_loss: 0.4560 - val_categorical_accuracy: 0.6439\n",
      "Epoch 101/124\n",
      "32298/32298 [==============================] - 408s 13ms/step - loss: 0.0195 - categorical_accuracy: 0.9767 - val_loss: 0.4594 - val_categorical_accuracy: 0.6322\n",
      "Epoch 102/124\n",
      "32298/32298 [==============================] - 387s 12ms/step - loss: 0.0187 - categorical_accuracy: 0.9774 - val_loss: 0.4995 - val_categorical_accuracy: 0.6110\n",
      "Epoch 103/124\n",
      "32298/32298 [==============================] - 406s 13ms/step - loss: 0.0181 - categorical_accuracy: 0.9786 - val_loss: 0.4452 - val_categorical_accuracy: 0.6495\n",
      "Epoch 104/124\n",
      "32298/32298 [==============================] - 366s 11ms/step - loss: 0.0195 - categorical_accuracy: 0.9773 - val_loss: 0.4556 - val_categorical_accuracy: 0.6459\n",
      "Epoch 105/124\n",
      "32298/32298 [==============================] - 399s 12ms/step - loss: 0.0190 - categorical_accuracy: 0.9767 - val_loss: 0.4546 - val_categorical_accuracy: 0.6225\n",
      "Epoch 106/124\n",
      "32298/32298 [==============================] - 425s 13ms/step - loss: 0.0183 - categorical_accuracy: 0.9783 - val_loss: 0.4837 - val_categorical_accuracy: 0.6244\n",
      "Epoch 107/124\n",
      "32298/32298 [==============================] - 455s 14ms/step - loss: 0.0181 - categorical_accuracy: 0.9783 - val_loss: 0.4341 - val_categorical_accuracy: 0.6517\n",
      "Epoch 108/124\n",
      "32298/32298 [==============================] - 444s 14ms/step - loss: 0.0179 - categorical_accuracy: 0.9779 - val_loss: 0.4484 - val_categorical_accuracy: 0.6303\n",
      "Epoch 109/124\n",
      "32298/32298 [==============================] - 391s 12ms/step - loss: 0.0187 - categorical_accuracy: 0.9771 - val_loss: 0.4514 - val_categorical_accuracy: 0.6461\n",
      "Epoch 110/124\n",
      "32298/32298 [==============================] - 381s 12ms/step - loss: 0.0180 - categorical_accuracy: 0.9782 - val_loss: 0.4741 - val_categorical_accuracy: 0.6199\n",
      "Epoch 111/124\n",
      "32298/32298 [==============================] - 386s 12ms/step - loss: 0.0184 - categorical_accuracy: 0.9772 - val_loss: 0.4555 - val_categorical_accuracy: 0.6124\n",
      "Epoch 112/124\n",
      "32298/32298 [==============================] - 378s 12ms/step - loss: 0.0175 - categorical_accuracy: 0.9788 - val_loss: 0.4479 - val_categorical_accuracy: 0.6509\n",
      "Epoch 113/124\n",
      "32298/32298 [==============================] - 388s 12ms/step - loss: 0.0175 - categorical_accuracy: 0.9792 - val_loss: 0.4626 - val_categorical_accuracy: 0.6408\n",
      "Epoch 114/124\n",
      "32298/32298 [==============================] - 423s 13ms/step - loss: 0.0172 - categorical_accuracy: 0.9793 - val_loss: 0.4736 - val_categorical_accuracy: 0.6481\n",
      "Epoch 115/124\n",
      "32298/32298 [==============================] - 408s 13ms/step - loss: 0.0170 - categorical_accuracy: 0.9796 - val_loss: 0.4533 - val_categorical_accuracy: 0.6556\n",
      "Epoch 116/124\n",
      "32298/32298 [==============================] - 431s 13ms/step - loss: 0.0171 - categorical_accuracy: 0.9791 - val_loss: 0.4878 - val_categorical_accuracy: 0.6264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/124\n",
      "32298/32298 [==============================] - 424s 13ms/step - loss: 0.0168 - categorical_accuracy: 0.9796 - val_loss: 0.4792 - val_categorical_accuracy: 0.6052\n",
      "Epoch 118/124\n",
      "32298/32298 [==============================] - 442s 14ms/step - loss: 0.0168 - categorical_accuracy: 0.9795 - val_loss: 0.4382 - val_categorical_accuracy: 0.6481\n",
      "Epoch 119/124\n",
      "32298/32298 [==============================] - 447s 14ms/step - loss: 0.0163 - categorical_accuracy: 0.9806 - val_loss: 0.4495 - val_categorical_accuracy: 0.6431\n",
      "Epoch 120/124\n",
      "32298/32298 [==============================] - 446s 14ms/step - loss: 0.0170 - categorical_accuracy: 0.9795 - val_loss: 0.4680 - val_categorical_accuracy: 0.6509\n",
      "Epoch 121/124\n",
      "32298/32298 [==============================] - 420s 13ms/step - loss: 0.0176 - categorical_accuracy: 0.9779 - val_loss: 0.4510 - val_categorical_accuracy: 0.6420\n",
      "Epoch 122/124\n",
      "32298/32298 [==============================] - 467s 14ms/step - loss: 0.0171 - categorical_accuracy: 0.9792 - val_loss: 0.4652 - val_categorical_accuracy: 0.6445\n",
      "Epoch 123/124\n",
      "32298/32298 [==============================] - 458s 14ms/step - loss: 0.0171 - categorical_accuracy: 0.9794 - val_loss: 0.4523 - val_categorical_accuracy: 0.6447\n",
      "Epoch 124/124\n",
      "32298/32298 [==============================] - 464s 14ms/step - loss: 0.0160 - categorical_accuracy: 0.9804 - val_loss: 0.4870 - val_categorical_accuracy: 0.6158\n",
      "[0 1 2 3 4 5 6]\n",
      "[[1.1084077e-07 1.8900730e-08 2.1301905e-09 ... 1.1218396e-05\n",
      "  5.5096762e-06 3.6505142e-03]\n",
      " [4.2329347e-08 4.2964338e-10 4.0855221e-07 ... 9.9997604e-01\n",
      "  2.0399551e-07 4.1505004e-08]\n",
      " [2.2885898e-01 1.1050628e-03 2.8002865e-03 ... 5.3604081e-04\n",
      "  9.3704104e-01 5.4209549e-03]\n",
      " ...\n",
      " [5.1894519e-03 5.1904179e-05 9.9395082e-05 ... 5.4554611e-01\n",
      "  2.0200614e-04 5.4753596e-01]\n",
      " [7.2893827e-06 2.4004859e-08 3.8702998e-04 ... 1.8614884e-02\n",
      "  1.4071377e-07 9.7744787e-01]\n",
      " [1.2689079e-02 2.1351323e-05 9.7870380e-01 ... 5.2452309e-04\n",
      "  4.1915794e-04 2.6321439e-02]]\n",
      "[2.15804979e-01 6.26211229e-04 3.64157924e-04 1.19352914e-01\n",
      " 1.22307998e-03 7.59692192e-01 2.51820381e-03]\n",
      "Predicted Emotion :  surprise\n",
      "Probability : 0.7596922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "# Functions to extract data from csv file and load into a pandas dataframe \n",
    "\n",
    "def load_data(file):\n",
    "    # columns of the data\n",
    "    columns=['emotion','pixels','usage']\n",
    "    # convert the csv data file into a dataframe \n",
    "    df=pd.read_csv(file,names=columns, na_filter=False)\n",
    "    # preview dataframe to see if it was successful\n",
    "    df.head(1)\n",
    "    return df\n",
    "def extract_features_and_labels(df):\n",
    "    X=[] # features/pixels nested array of pixels\n",
    "    Y=[] # Labels\n",
    "    for index, row in df.iterrows():\n",
    "        if(index!=0):\n",
    "            \n",
    "            Y.append(int(row['emotion']))\n",
    "            X.append([int(p) for p in row['pixels'].split()]) # create array of pixel\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y\n",
    "def cnn_model(num_class):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1 - Convolution\n",
    "    model.add(Conv2D(64,(3,3), border_mode='same', input_shape=(48, 48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 2nd Convolution layer\n",
    "    model.add(Conv2D(128,(5,5), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 3rd Convolution layer\n",
    "    model.add(Conv2D(512,(3,3), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 4th Convolution layer\n",
    "    model.add(Conv2D(512,(3,3), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layer 1st layer\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    # Fully connected layer 2nd layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(num_class, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[categorical_accuracy])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    \n",
    "    print(\"Predicted Emotion : \", objects[np.argmax(emotions)])\n",
    "    print(\"Probability :\",np.max(emotions))\n",
    "\n",
    "def make_prediction(model):\n",
    "    img = image.load_img('Data/disgust.jpeg', grayscale=True, target_size=(48, 48))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x /= 255\n",
    "\n",
    "    custom = model.predict(x)\n",
    "    print(custom[0])\n",
    "    emotion_analysis(custom[0])\n",
    "    \n",
    "        \n",
    "def ml_pipeline(file):\n",
    "    # labels \n",
    "    labels = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    # load data \n",
    "    df = load_data(file)\n",
    "    XY = extract_features_and_labels(df)\n",
    "    X, Y = XY\n",
    "    print(\"X shape\", X.shape)\n",
    "    print(\"Y shape\", Y.shape)\n",
    "    num_class = len(set(Y))\n",
    "    print(num_class)\n",
    "    # keras with tensorflow backend\n",
    "    N, D = X.shape\n",
    "    X = X.reshape(N, 48, 48, 1)\n",
    "    \n",
    "    #Split the data, 90% training and 10% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "    y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
    "    y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)\n",
    "    \n",
    "    # create model architure \n",
    "    #model=cnn_model(num_class)\n",
    "    K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
    "    model=cnn_model(num_class)\n",
    "    K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n",
    "    \n",
    "    fitted=model.fit(\n",
    "            x=X_train,     \n",
    "            y=y_train, \n",
    "            batch_size=128,\n",
    "            epochs=124, \n",
    "            verbose=1, \n",
    "            validation_data=(X_test,y_test),\n",
    "            shuffle=True\n",
    "            )\n",
    "    \n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    print(y_pos)\n",
    "    \n",
    "    #shape\n",
    "    y_pred=model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    y_test.shape\n",
    "    \n",
    "    make_prediction(model)\n",
    "    #save trained model\n",
    "    joblib.dump(model, \"./production.joblib\", compress=True)\n",
    "    \n",
    "ml_pipeline('Data/data.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load(\"production.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_analysis(emotions):\n",
    "    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    \n",
    "    print(\"Predicted Emotion : \", objects[np.argmax(emotions)])\n",
    "    print(\"Probability :\",np.max(emotions))\n",
    "\n",
    "def make_prediction(model):\n",
    "    img = image.load_img('Data/h.jpeg', grayscale=True, target_size=(48, 48))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x /= 255\n",
    "\n",
    "    custom = model.predict(x)\n",
    "    print(custom[0])\n",
    "    emotion_analysis(custom[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1393133e-09 8.0246356e-14 4.5902129e-10 9.9999952e-01 5.7060974e-11\n",
      " 2.2600402e-10 4.4909416e-14]\n",
      "Predicted Emotion :  happy\n",
      "Probability : 0.9999995\n"
     ]
    }
   ],
   "source": [
    "make_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
