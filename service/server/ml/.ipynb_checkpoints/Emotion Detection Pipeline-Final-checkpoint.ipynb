{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Library Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (35887, 2304)\n",
      "Y shape (35887,)\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(48, 48, 1..., padding=\"same\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), padding=\"same\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\")`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 4,478,727\n",
      "Trainable params: 4,474,759\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n",
      "Train on 32298 samples, validate on 3589 samples\n",
      "Epoch 1/40\n",
      "32298/32298 [==============================] - 462s 14ms/step - loss: 0.3678 - categorical_accuracy: 0.3532 - val_loss: 0.4081 - val_categorical_accuracy: 0.2951\n",
      "Epoch 2/40\n",
      "32298/32298 [==============================] - 435s 13ms/step - loss: 0.2982 - categorical_accuracy: 0.4926 - val_loss: 0.2798 - val_categorical_accuracy: 0.5266\n",
      "Epoch 3/40\n",
      "32298/32298 [==============================] - 439s 14ms/step - loss: 0.2755 - categorical_accuracy: 0.5409 - val_loss: 0.3122 - val_categorical_accuracy: 0.4570\n",
      "Epoch 4/40\n",
      "32298/32298 [==============================] - 434s 13ms/step - loss: 0.2607 - categorical_accuracy: 0.5712 - val_loss: 0.2888 - val_categorical_accuracy: 0.5104\n",
      "Epoch 5/40\n",
      "32298/32298 [==============================] - 411s 13ms/step - loss: 0.2498 - categorical_accuracy: 0.5935 - val_loss: 0.2698 - val_categorical_accuracy: 0.5439\n",
      "Epoch 6/40\n",
      "32298/32298 [==============================] - 412s 13ms/step - loss: 0.2403 - categorical_accuracy: 0.6112 - val_loss: 0.2911 - val_categorical_accuracy: 0.5113\n",
      "Epoch 7/40\n",
      "32298/32298 [==============================] - 408s 13ms/step - loss: 0.2318 - categorical_accuracy: 0.6292 - val_loss: 0.2515 - val_categorical_accuracy: 0.5929\n",
      "Epoch 8/40\n",
      "32298/32298 [==============================] - 419s 13ms/step - loss: 0.2220 - categorical_accuracy: 0.6487 - val_loss: 0.2680 - val_categorical_accuracy: 0.5628\n",
      "Epoch 9/40\n",
      "32298/32298 [==============================] - 409s 13ms/step - loss: 0.2121 - categorical_accuracy: 0.6673 - val_loss: 0.2602 - val_categorical_accuracy: 0.5751\n",
      "Epoch 10/40\n",
      "32298/32298 [==============================] - 408s 13ms/step - loss: 0.2026 - categorical_accuracy: 0.6867 - val_loss: 0.2491 - val_categorical_accuracy: 0.6041\n",
      "Epoch 11/40\n",
      "32298/32298 [==============================] - 407s 13ms/step - loss: 0.1905 - categorical_accuracy: 0.7078 - val_loss: 0.2428 - val_categorical_accuracy: 0.6030\n",
      "Epoch 12/40\n",
      "32298/32298 [==============================] - 412s 13ms/step - loss: 0.1818 - categorical_accuracy: 0.7248 - val_loss: 0.3715 - val_categorical_accuracy: 0.4706\n",
      "Epoch 13/40\n",
      "32298/32298 [==============================] - 412s 13ms/step - loss: 0.1698 - categorical_accuracy: 0.7442 - val_loss: 0.2578 - val_categorical_accuracy: 0.6110\n",
      "Epoch 14/40\n",
      "32298/32298 [==============================] - 409s 13ms/step - loss: 0.1597 - categorical_accuracy: 0.7639 - val_loss: 0.2374 - val_categorical_accuracy: 0.6272\n",
      "Epoch 15/40\n",
      "32298/32298 [==============================] - 406s 13ms/step - loss: 0.1483 - categorical_accuracy: 0.7813 - val_loss: 0.2515 - val_categorical_accuracy: 0.6113\n",
      "Epoch 16/40\n",
      "32298/32298 [==============================] - 409s 13ms/step - loss: 0.1405 - categorical_accuracy: 0.7975 - val_loss: 0.2526 - val_categorical_accuracy: 0.6208\n",
      "Epoch 17/40\n",
      "32298/32298 [==============================] - 432s 13ms/step - loss: 0.1290 - categorical_accuracy: 0.8159 - val_loss: 0.2902 - val_categorical_accuracy: 0.5846\n",
      "Epoch 18/40\n",
      "32298/32298 [==============================] - 409s 13ms/step - loss: 0.1210 - categorical_accuracy: 0.8267 - val_loss: 0.3043 - val_categorical_accuracy: 0.5926\n",
      "Epoch 19/40\n",
      "32298/32298 [==============================] - 407s 13ms/step - loss: 0.1128 - categorical_accuracy: 0.8414 - val_loss: 0.2626 - val_categorical_accuracy: 0.6417\n",
      "Epoch 20/40\n",
      "32298/32298 [==============================] - 404s 13ms/step - loss: 0.1049 - categorical_accuracy: 0.8549 - val_loss: 0.2730 - val_categorical_accuracy: 0.6386\n",
      "Epoch 21/40\n",
      "32298/32298 [==============================] - 411s 13ms/step - loss: 0.0982 - categorical_accuracy: 0.8651 - val_loss: 0.2727 - val_categorical_accuracy: 0.6375\n",
      "Epoch 22/40\n",
      "32298/32298 [==============================] - 411s 13ms/step - loss: 0.0916 - categorical_accuracy: 0.8745 - val_loss: 0.2988 - val_categorical_accuracy: 0.6239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      "32298/32298 [==============================] - 401s 12ms/step - loss: 0.0866 - categorical_accuracy: 0.8800 - val_loss: 0.2908 - val_categorical_accuracy: 0.6467\n",
      "Epoch 24/40\n",
      "32298/32298 [==============================] - 403s 12ms/step - loss: 0.0806 - categorical_accuracy: 0.8908 - val_loss: 0.3239 - val_categorical_accuracy: 0.6102\n",
      "Epoch 25/40\n",
      "32298/32298 [==============================] - 412s 13ms/step - loss: 0.0772 - categorical_accuracy: 0.8951 - val_loss: 0.3437 - val_categorical_accuracy: 0.6071\n",
      "Epoch 26/40\n",
      "32298/32298 [==============================] - 415s 13ms/step - loss: 0.0730 - categorical_accuracy: 0.9018 - val_loss: 0.3187 - val_categorical_accuracy: 0.6241\n",
      "Epoch 27/40\n",
      "32298/32298 [==============================] - 403s 12ms/step - loss: 0.0700 - categorical_accuracy: 0.9059 - val_loss: 0.3854 - val_categorical_accuracy: 0.5731\n",
      "Epoch 28/40\n",
      "32298/32298 [==============================] - 402s 12ms/step - loss: 0.0660 - categorical_accuracy: 0.9141 - val_loss: 0.3163 - val_categorical_accuracy: 0.6428\n",
      "Epoch 29/40\n",
      "32298/32298 [==============================] - 378s 12ms/step - loss: 0.0641 - categorical_accuracy: 0.9141 - val_loss: 0.3329 - val_categorical_accuracy: 0.6199\n",
      "Epoch 30/40\n",
      "32298/32298 [==============================] - 391s 12ms/step - loss: 0.0602 - categorical_accuracy: 0.9225 - val_loss: 0.3610 - val_categorical_accuracy: 0.6247\n",
      "Epoch 31/40\n",
      "32298/32298 [==============================] - 406s 13ms/step - loss: 0.0593 - categorical_accuracy: 0.9245 - val_loss: 0.3500 - val_categorical_accuracy: 0.6266\n",
      "Epoch 32/40\n",
      "32298/32298 [==============================] - 398s 12ms/step - loss: 0.0559 - categorical_accuracy: 0.9287 - val_loss: 0.3630 - val_categorical_accuracy: 0.6108\n",
      "Epoch 33/40\n",
      "32298/32298 [==============================] - 398s 12ms/step - loss: 0.0552 - categorical_accuracy: 0.9295 - val_loss: 0.3706 - val_categorical_accuracy: 0.6088\n",
      "Epoch 34/40\n",
      "32298/32298 [==============================] - 393s 12ms/step - loss: 0.0534 - categorical_accuracy: 0.9316 - val_loss: 0.4496 - val_categorical_accuracy: 0.5361\n",
      "Epoch 35/40\n",
      "32298/32298 [==============================] - 416s 13ms/step - loss: 0.0520 - categorical_accuracy: 0.9336 - val_loss: 0.3463 - val_categorical_accuracy: 0.6436\n",
      "Epoch 36/40\n",
      "32298/32298 [==============================] - 402s 12ms/step - loss: 0.0516 - categorical_accuracy: 0.9330 - val_loss: 0.3959 - val_categorical_accuracy: 0.5999\n",
      "Epoch 37/40\n",
      "32298/32298 [==============================] - 424s 13ms/step - loss: 0.0481 - categorical_accuracy: 0.9399 - val_loss: 0.3906 - val_categorical_accuracy: 0.5993\n",
      "Epoch 38/40\n",
      "32298/32298 [==============================] - 434s 13ms/step - loss: 0.0464 - categorical_accuracy: 0.9427 - val_loss: 0.4130 - val_categorical_accuracy: 0.5943\n",
      "Epoch 39/40\n",
      "32298/32298 [==============================] - 431s 13ms/step - loss: 0.0474 - categorical_accuracy: 0.9393 - val_loss: 0.3560 - val_categorical_accuracy: 0.6453\n",
      "Epoch 40/40\n",
      "32298/32298 [==============================] - 430s 13ms/step - loss: 0.0445 - categorical_accuracy: 0.9431 - val_loss: 0.3632 - val_categorical_accuracy: 0.6506\n",
      "[0 1 2 3 4 5 6]\n",
      "[[3.7963287e-05 6.6285469e-07 2.6194612e-05 ... 1.8461268e-04\n",
      "  3.3972267e-07 2.7079190e-05]\n",
      " [1.4374637e-03 1.0132271e-05 1.0551436e-02 ... 9.7879511e-01\n",
      "  9.2700159e-04 1.6834038e-06]\n",
      " [6.1118831e-03 1.3404781e-06 1.8841110e-01 ... 6.9614725e-06\n",
      "  8.9714575e-01 6.6919463e-05]\n",
      " ...\n",
      " [1.1886231e-03 1.3671143e-05 2.5467804e-02 ... 3.6793056e-01\n",
      "  4.8005812e-05 5.9718353e-01]\n",
      " [4.9555052e-02 3.6944095e-07 1.3682965e-04 ... 1.5199273e-03\n",
      "  1.1423404e-06 9.6672308e-01]\n",
      " [1.3632661e-01 3.1819236e-05 8.4976006e-01 ... 1.9414657e-03\n",
      "  2.2230737e-03 9.6272528e-03]]\n",
      "[9.2173721e-08 2.3919525e-12 3.3511675e-05 9.9991834e-01 8.2983687e-10\n",
      " 1.9119389e-06 2.5205071e-10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "# Functions to extract data from csv file and load into a pandas dataframe \n",
    "\n",
    "def load_data(file):\n",
    "    # columns of the data\n",
    "    columns=['emotion','pixels','usage']\n",
    "    # convert the csv data file into a dataframe \n",
    "    df=pd.read_csv(file,names=columns, na_filter=False)\n",
    "    # preview dataframe to see if it was successful\n",
    "    df.head(1)\n",
    "    return df\n",
    "def extract_features_and_labels(df):\n",
    "    X=[] # features/pixels nested array of pixels\n",
    "    Y=[] # Labels\n",
    "    for index, row in df.iterrows():\n",
    "        if(index!=0):\n",
    "            \n",
    "            Y.append(int(row['emotion']))\n",
    "            X.append([int(p) for p in row['pixels'].split()]) # create array of pixel\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y\n",
    "def cnn_model(num_class):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1 - Convolution\n",
    "    model.add(Conv2D(64,(3,3), border_mode='same', input_shape=(48, 48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 2nd Convolution layer\n",
    "    model.add(Conv2D(128,(5,5), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 3rd Convolution layer\n",
    "    model.add(Conv2D(512,(3,3), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # 4th Convolution layer\n",
    "    model.add(Conv2D(512,(3,3), border_mode='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layer 1st layer\n",
    "    model.add(Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    # Fully connected layer 2nd layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(num_class, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[categorical_accuracy])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    \n",
    "    print(\"Predicted Emotion : \", objects[np.argmax(emotions)])\n",
    "    print(\"Probability :\",np.max(emotions))\n",
    "\n",
    "def make_prediction(model):\n",
    "    img = image.load_img('Data/disgust.jpeg', grayscale=True, target_size=(48, 48))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x /= 255\n",
    "\n",
    "    custom = model.predict(x)\n",
    "    print(custom[0])\n",
    "    emotion_analysis(custom[0])\n",
    "    \n",
    "        \n",
    "def ml_pipeline(file):\n",
    "    # labels \n",
    "    labels = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    # load data \n",
    "    df = load_data(file)\n",
    "    XY = extract_features_and_labels(df)\n",
    "    X, Y = XY\n",
    "    print(\"X shape\", X.shape)\n",
    "    print(\"Y shape\", Y.shape)\n",
    "    num_class = len(set(Y))\n",
    "    print(num_class)\n",
    "    # keras with tensorflow backend\n",
    "    N, D = X.shape\n",
    "    X = X.reshape(N, 48, 48, 1)\n",
    "    \n",
    "    #Split the data, 90% training and 10% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "    y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
    "    y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)\n",
    "    \n",
    "    # create model architure \n",
    "    #model=cnn_model(num_class)\n",
    "    K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
    "    model=cnn_model(num_class)\n",
    "    K.set_value(model.optimizer.lr,1e-3) # set the learning rate\n",
    "    \n",
    "    fitted=model.fit(\n",
    "            x=X_train,     \n",
    "            y=y_train, \n",
    "            batch_size=128,\n",
    "            epochs=124, \n",
    "            verbose=1, \n",
    "            validation_data=(X_test,y_test),\n",
    "            shuffle=True\n",
    "            )\n",
    "    \n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    print(y_pos)\n",
    "    \n",
    "    #shape\n",
    "    y_pred=model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    y_test.shape\n",
    "    \n",
    "    make_prediction(model)\n",
    "    #save trained model\n",
    "    joblib.dump(model, \"./production.joblib\", compress=True)\n",
    "    \n",
    "ml_pipeline('Data/data.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model = joblib.load(\"production.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_analysis(emotions):\n",
    "    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "    \n",
    "    print(\"Predicted Emotion : \", objects[np.argmax(emotions)])\n",
    "    print(\"Probability :\",np.max(emotions))\n",
    "\n",
    "def make_prediction(model):\n",
    "    img = image.load_img('Data/disgust.jpeg', grayscale=True, target_size=(48, 48))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x /= 255\n",
    "\n",
    "    custom = model.predict(x)\n",
    "    print(custom[0])\n",
    "    emotion_analysis(custom[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5204458  0.01516402 0.11435542 0.00455959 0.00608824 0.03723133\n",
      " 0.24769847]\n",
      "Predicted Emotion :  angry\n",
      "Probability : 0.5204458\n"
     ]
    }
   ],
   "source": [
    "make_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
